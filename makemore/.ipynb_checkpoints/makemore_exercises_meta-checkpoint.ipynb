{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Implementation for Make_more exercises\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=open(\"C:/Users/andre/ScratchNeuralNet/makemore/names.txt\",'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2084814"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  12857541\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [],[]\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = int(xs.nelement()/2)\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3638505935668945\n",
      "3.0354621410369873\n",
      "2.8623170852661133\n",
      "2.7533929347991943\n",
      "2.6771767139434814\n",
      "2.619142532348633\n",
      "2.573092460632324\n",
      "2.5355896949768066\n",
      "2.5045855045318604\n",
      "2.478623151779175\n",
      "2.4566495418548584\n",
      "2.4378390312194824\n",
      "2.4215784072875977\n",
      "2.4073855876922607\n",
      "2.394890069961548\n",
      "2.3838067054748535\n",
      "2.37390398979187\n",
      "2.365002155303955\n",
      "2.3569533824920654\n",
      "2.3496389389038086\n",
      "2.3429603576660156\n",
      "2.3368353843688965\n",
      "2.3311984539031982\n",
      "2.3259923458099365\n",
      "2.3211679458618164\n",
      "2.316685438156128\n",
      "2.312506914138794\n",
      "2.308602809906006\n",
      "2.3049464225769043\n",
      "2.301515579223633\n",
      "2.2982892990112305\n",
      "2.2952497005462646\n",
      "2.2923805713653564\n",
      "2.289668560028076\n",
      "2.287100315093994\n",
      "2.284666061401367\n",
      "2.282355308532715\n",
      "2.2801594734191895\n",
      "2.2780702114105225\n",
      "2.2760801315307617\n",
      "2.274182081222534\n",
      "2.2723705768585205\n",
      "2.2706401348114014\n",
      "2.2689855098724365\n",
      "2.267401695251465\n",
      "2.2658843994140625\n",
      "2.264430046081543\n",
      "2.263035297393799\n",
      "2.261695384979248\n",
      "2.260408639907837\n",
      "2.2591712474823\n",
      "2.2579808235168457\n",
      "2.2568347454071045\n",
      "2.255730628967285\n",
      "2.2546660900115967\n",
      "2.2536399364471436\n",
      "2.2526495456695557\n",
      "2.2516932487487793\n",
      "2.2507688999176025\n",
      "2.249875545501709\n",
      "2.249011993408203\n",
      "2.248175621032715\n",
      "2.2473666667938232\n",
      "2.246582508087158\n",
      "2.2458229064941406\n",
      "2.245086431503296\n",
      "2.2443723678588867\n",
      "2.2436795234680176\n",
      "2.243006944656372\n",
      "2.242353677749634\n",
      "2.2417187690734863\n",
      "2.2411019802093506\n",
      "2.24050235748291\n",
      "2.2399189472198486\n",
      "2.239351511001587\n",
      "2.2387993335723877\n",
      "2.2382616996765137\n",
      "2.2377376556396484\n",
      "2.237227439880371\n",
      "2.236729860305786\n",
      "2.2362451553344727\n",
      "2.235772132873535\n",
      "2.2353107929229736\n",
      "2.23486065864563\n",
      "2.234421491622925\n",
      "2.233992099761963\n",
      "2.2335734367370605\n",
      "2.2331643104553223\n",
      "2.23276424407959\n",
      "2.2323737144470215\n",
      "2.2319915294647217\n",
      "2.2316176891326904\n",
      "2.2312521934509277\n",
      "2.2308948040008545\n",
      "2.2305445671081543\n",
      "2.2302021980285645\n",
      "2.2298669815063477\n",
      "2.2295384407043457\n",
      "2.229217052459717\n",
      "2.2289021015167236\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# gradient descent with F.cross_entropy()\n",
    "for k in range(100):\n",
    "    \n",
    "    # forward pass\n",
    "    first_rows = W[xs[:, 0], :]\n",
    "    sec_rows = W[xs[:, 1] + 27, :]\n",
    "    logits = first_rows + sec_rows  # predict log-counts\n",
    "    probs = F.softmax(logits, dim=1)  # compute the probabilities\n",
    "    loss = F.cross_entropy(logits, ys) + 0.001*(W**2).mean()  # compute the loss\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None  # set to zero the gradient\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the weights\n",
    "    W.data += -50 * W.grad\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 2.3938\n",
      "Loss after epoch 2: 2.3881\n",
      "Loss after epoch 3: 2.3841\n",
      "Loss after epoch 4: 2.3812\n",
      "Loss after epoch 5: 2.3790\n",
      "Loss after epoch 6: 2.3772\n",
      "Loss after epoch 7: 2.3758\n",
      "Loss after epoch 8: 2.3747\n",
      "Loss after epoch 9: 2.3737\n",
      "Loss after epoch 10: 2.3730\n",
      "Loss after epoch 11: 2.3723\n",
      "Loss after epoch 12: 2.3718\n",
      "Loss after epoch 13: 2.3713\n",
      "Loss after epoch 14: 2.3710\n",
      "Loss after epoch 15: 2.3706\n",
      "Loss after epoch 16: 2.3704\n",
      "Loss after epoch 17: 2.3701\n",
      "Loss after epoch 18: 2.3699\n",
      "Loss after epoch 19: 2.3698\n",
      "Loss after epoch 20: 2.3696\n",
      "Loss after epoch 21: 2.3695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-cef1f0f4d05a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# set to zero the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# using Adam optimizer instead of stochaistic gradient descent\n",
    "batch_size = 128\n",
    "optimizer = torch.optim.Adam([W], lr=0.001)\n",
    "for k in range(100):\n",
    "    for xb, yb in zip(xs.chunk(batch_size), ys.chunk(batch_size)):\n",
    "        # forward pass\n",
    "        first_rows = W[xb[:, 0], :]\n",
    "        sec_rows = W[xb[:, 1] + 27, :]\n",
    "        logits = first_rows + sec_rows  # predict log-counts\n",
    "#         probs = F.softmax(logits, dim=1)  # compute the probabilities\n",
    "        loss = F.cross_entropy(logits, yb) + 0.001*(W**2).mean()  # compute the loss\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()  # set to zero the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "    print('Loss after epoch {}: {:.4f}'.format(k+1, loss.item()))\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oreshan.\n",
      "aznavina.\n",
      "urunagedddaniablazargele.\n",
      "oubrickoryaninai.\n",
      "onevaardfin.\n",
      "uialusefers.\n",
      "aunnhishenitoy.\n",
      "aminallitr.\n",
      "rychaaancheryn.\n",
      "orishaliuanechyn.\n",
      "ashiesh.\n",
      "baenelee.\n",
      "arniaharnthan.\n",
      "odorsi.\n",
      "adyhazyvi.\n",
      "comaklienes.\n",
      "cvorey.\n",
      "arrebrichis.\n",
      "aalyas.\n",
      "ondeneymupig.\n",
      "aniyinneerly.\n",
      "arelma.\n",
      "adarmerickarsseli.\n",
      "unastaniely.\n",
      "aynorthenn.\n",
      "haaludeetita.\n",
      "tarlandoryanusava.\n",
      "rucarmizarethaslan.\n",
      "ahatina.\n",
      "ionnechil.\n",
      "mariharete.\n",
      "oleyon.\n",
      "orleckeaniea.\n",
      "aliena.\n",
      "enyanella.\n",
      "ambery.\n",
      "onenor.\n",
      "hanabiricon.\n",
      "mangowon.\n",
      "araaliardilan.\n",
      "otaaphwistaley.\n",
      "ahdcea.\n",
      "harional.\n",
      "aucheinayn.\n",
      "piryanel.\n",
      "alberithakh.\n",
      "aaucain.\n",
      "aslanimarne.\n",
      "orlelumikathraderesilaven.\n",
      "jorlishia.\n",
      "ahubet.\n",
      "arenaerone.\n",
      "oletkahmahina.\n",
      "annatee.\n",
      "aratsm.\n",
      "urinra.\n",
      "auholienie.\n",
      "orchol.\n",
      "andaul.\n",
      "alitadane.\n",
      "dennnjubilaielesphairachedariale.\n",
      "aroasas.\n",
      "onartakan.\n",
      "andyoneeets.\n",
      "arronserk.\n",
      "nanobwauverti.\n",
      "saellima.\n",
      "onelbey.\n",
      "ironarettrnn.\n",
      "ylaelyn.\n",
      "bycerraynnee.\n",
      "orbarleein.\n",
      "saddjaeluvialver.\n",
      "arvaigervenmanne.\n",
      "wanayna.\n",
      "audkblen.\n",
      "alliague.\n",
      "aanigerron.\n",
      "owshaynimmi.\n",
      "arlette.\n",
      "tafria.\n",
      "ahorlynd.\n",
      "shnene.\n",
      "ahurett.\n",
      "audreorse.\n",
      "albobaaverda.\n",
      "yaarinu.\n",
      "herlia.\n",
      "alonek.\n",
      "onniena.\n",
      "onahuon.\n",
      "aryotmara.\n",
      "mardylecle.\n",
      "awivikk.\n",
      "amranine.\n",
      "ahoflia.\n",
      "ofverl.\n",
      "raxjahelmissenmambyrnejamenn.\n",
      "onuihene.\n",
      "onaraarse.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2247403657)\n",
    "\n",
    "out = []\n",
    "ix = 0\n",
    "iy = 0\n",
    "# xenc = F.one_hot(torch.tensor([ix, iy]), num_classes=27).float() # TODO: I need to input two values to trigram model!\n",
    "# xenc = xenc.reshape(-1, 54)\n",
    "# xenc\n",
    "    \n",
    "for i in range(100):\n",
    "    \n",
    "    out = []\n",
    "    ix = 0\n",
    "    iy = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix, iy]), num_classes=27).float()\n",
    "        xenc = xenc.reshape(-1,54) # (num_of_examples, vocab_size*2)\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "        # print(p.shape)\n",
    "        # ------------\n",
    "        \n",
    "        ix = iy\n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "#         if iy != 0:\n",
    "        out.append(itos[iy])\n",
    "#         if iy == 0 and len(out) > 5: \n",
    "        if iy == 0: \n",
    "            out.append('.')\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
